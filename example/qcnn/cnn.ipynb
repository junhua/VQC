{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "X_train = torch.rand(350, 3, 3)\n",
    "Y_train = (torch.sum(X_train>0.5, dim=(1,2))>4).float()\n",
    "X_test = torch.rand(150, 3, 3)\n",
    "Y_test = (torch.sum(X_test>0.5, dim=(1,2))>4).float()\n",
    "\n",
    "data = {}\n",
    "data['x_train']=X_train.numpy().tolist()\n",
    "data['y_train']=Y_train.numpy().tolist()\n",
    "data['x_test']=X_test.numpy().tolist()\n",
    "data['y_test']=Y_test.numpy().tolist()\n",
    "\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(data, fp)\n",
    "\n",
    "# with open('data.json') as json_file:\n",
    "#     data = json.load(json_file)\n",
    "\n",
    "# X_train = torch.FloatTensor(data['x_train'])\n",
    "# Y_train = torch.FloatTensor(data['y_train'])\n",
    "# X_test = torch.FloatTensor(data['x_test'])\n",
    "# Y_test = torch.FloatTensor(data['y_test'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 3x3 tetrics data \n",
    "import numpy as np\n",
    "import json\n",
    "cords = {}\n",
    "cords['S'] = np.array([\n",
    "    [[1,1,0], [0,1,1], [0,0,0]], \n",
    "    [[0,0,0], [1,1,0], [0,1,1]], \n",
    "    [[0,1,0], [1,1,0], [1,0,0]], \n",
    "    [[0,0,1], [0,1,1], [0,1,0]],\n",
    "    [[0,1,1], [1,1,0], [0,0,0]], \n",
    "    [[0,0,0], [0,1,1], [1,1,0]], \n",
    "    [[1,0,0], [1,1,0], [0,1,0]],\n",
    "    [[0,1,0], [0,1,1], [0,0,1]],\n",
    "])\n",
    "\n",
    "cords['T'] = np.array([\n",
    "    [[1,1,1], [0,1,0], [0,0,0]], \n",
    "    [[0,0,0], [1,1,1], [0,1,0]], \n",
    "    [[0,0,1], [0,1,1], [0,0,1]],\n",
    "    [[0,1,0], [1,1,0], [0,1,0]],\n",
    "    [[0,1,0], [1,1,1], [0,0,0]],\n",
    "    [[0,0,0], [0,1,0], [1,1,1]],\n",
    "    [[1,0,0], [1,1,0], [1,0,0]],\n",
    "    [[0,1,0], [0,1,1], [0,1,0]],\n",
    "])\n",
    "\n",
    "cords['L'] = np.array([\n",
    "    [[1,1,1], [0,0,1], [0,0,0]], \n",
    "    [[0,0,0], [1,1,1], [0,0,1]], \n",
    "    [[1,1,1], [1,0,0], [0,0,0]], \n",
    "    [[0,0,0], [1,1,1], [1,0,0]], \n",
    "    [[1,0,0], [1,1,1], [0,0,0]], \n",
    "    [[0,0,0], [1,0,0], [1,1,1]], \n",
    "    [[0,0,1], [1,1,1], [0,0,0]], \n",
    "    [[0,0,0], [0,0,1], [1,1,1]], \n",
    "    [[1,0,0], [1,0,0], [1,1,0]], \n",
    "    [[0,1,0], [0,1,0], [0,1,1]], \n",
    "    [[0,1,0], [0,1,0], [1,1,0]],\n",
    "    [[0,0,1], [0,0,1], [0,1,1]],\n",
    "    [[0,1,1], [0,1,0], [0,1,0]],\n",
    "    [[1,1,0], [0,1,0], [0,1,0]],\n",
    "    [[1,1,0], [1,0,0], [1,0,0]],\n",
    "    [[0,1,1], [0,0,1], [0,0,1]],        \n",
    "])\n",
    "\n",
    "cords['O'] = np.array([\n",
    "    [[1,1,0], [1,1,0], [0,0,0]], \n",
    "    [[0,1,1], [0,1,1], [0,0,0]], \n",
    "    [[0,0,0], [1,1,0], [1,1,0]],     \n",
    "    [[0,0,0], [0,1,1], [0,1,1]], \n",
    "])\n",
    "\n",
    "cords['I'] = np.array([\n",
    "    [[1,0,0], [1,0,0], [1,0,0]], \n",
    "    [[0,1,0], [0,1,0], [0,1,0]], \n",
    "    [[0,0,1], [0,0,1], [0,0,1]],     \n",
    "    [[1,1,1], [0,0,0], [0,0,0]], \n",
    "    [[0,0,0], [1,1,1], [0,0,0]], \n",
    "    [[0,0,0], [0,0,0], [1,1,1]], \n",
    "])\n",
    "\n",
    "# print(np.concatenate((cords['S'],cords['S'])))\n",
    "\n",
    "sample_size_each = 200\n",
    "\n",
    "test = {}\n",
    "train = {}\n",
    "\n",
    "\n",
    "for key in cords.keys():\n",
    "    \n",
    "    for item in cords[key]:\n",
    "        if key not in test.keys():\n",
    "            test[key] = (np.random.random((1,3,3)) / 4 + 0.7) * item + np.random.random((1,3,3))/10\n",
    "        else:\n",
    "            test[key] = np.concatenate((test[key], (np.random.random((1,3,3)) / 4 + 0.7) * item + np.random.random((1,3,3))/10))\n",
    "\n",
    "        if key not in train.keys():\n",
    "            train[key] = (np.random.random((1,3,3)) / 4 + 0.7) * item + np.random.random((1,3,3))/10\n",
    "        else:\n",
    "            train[key] = np.concatenate((train[key], (np.random.random((1,3,3)) / 4 + 0.7) * item + np.random.random((1,3,3))/10))\n",
    "\n",
    "\n",
    "    r_test = int(sample_size_each / len(cords[key]) * 0.2) - len(cords[key])\n",
    "    r_train = r_test * 4 - len(cords[key])\n",
    "    \n",
    "    for _ in range(r_test):\n",
    "        for item in cords[key]:\n",
    "            test[key] = np.concatenate((test[key], (np.random.random((1,3,3)) / 4 + 0.7) * item + np.random.random((1,3,3))/10))\n",
    "\n",
    "    for _ in range(r_train):\n",
    "        for item in cords[key]:\n",
    "            train[key] = np.concatenate((train[key], (np.random.random((1,3,3)) / 4 + 0.7) * item + np.random.random((1,3,3))/10))\n",
    "\n",
    "for key in test.keys():\n",
    "    test[key] = test[key].tolist()\n",
    "    train[key] = train[key].tolist()\n",
    "    \n",
    "\n",
    "with open('tetris_train.json', 'w') as fp:\n",
    "    json.dump(train, fp)\n",
    "\n",
    "with open('tetris_test.json', 'w') as fp:\n",
    "    json.dump(test, fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 3, 2)\n",
    "        self.conv2 = nn.Conv2d(3, 3, 2)\n",
    "#         self.conv1 = nn.Conv2d(1, 2, 3, padding=1)\n",
    "#         self.mp1 = nn.MaxPool2d(3, stride=1, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(2, 3, 3, padding=1)\n",
    "#         self.mp2 = nn.MaxPool2d(3, stride=1, padding=1)\n",
    "#         self.mp = nn.MaxPool2d(2, stride=1)\n",
    "        self.fc = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "#         x = self.mp1(F.relu(self.conv1(x)))\n",
    "#         x = self.mp2(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        \n",
    "        x = x.view(in_size, -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = ConvNet()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "#\n",
    "# Print number of parameters\n",
    "#\n",
    "for item in list(ConvNet().parameters()):\n",
    "    print (item)\n",
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "\n",
    "get_n_params(ConvNet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Training\n",
    "# \n",
    "results = {} #{iter: [loss, accuracy]}\n",
    "for epoch in range(1000):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i in range(len(Y_train)):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = X_train[i], torch.tensor([Y_train[i]])\n",
    "        inputs = inputs.view(1,1,len(inputs), len(inputs))\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        # print(outputs.squeeze(0), labels)\n",
    "        loss = criterion(outputs.squeeze(0), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    if epoch % 10 == 9:\n",
    "        print (\"Epoch: %d, Loss: %.3f\"%(epoch+1, running_loss))\n",
    "\n",
    "        correct = 0.\n",
    "        total = float(len(Y_test))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(Y_test)):\n",
    "                images, labels = X_test[i], torch.tensor(Y_test[i])\n",
    "                images = images.view(1,1,len(images), len(images))\n",
    "\n",
    "                output = model(images)\n",
    "                predicted = output.data > 0.5\n",
    "                correct += (int(predicted[0]) == int(labels))\n",
    "                accuracy = 100. * correct / total\n",
    "        print('Accuracy of the network: %.2f %%' % (accuracy))\n",
    "        \n",
    "        results[epoch+1] = [running_loss, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.json', 'w') as fp:\n",
    "    json.dump(results, fp)\n",
    "    \n",
    "\n",
    "# correct = 0.\n",
    "# total = float(len(Y_test))\n",
    "\n",
    "# outputs = []\n",
    "# with torch.no_grad():\n",
    "#     for i in range(len(Y_test)):\n",
    "#         images, labels = X_test[i], torch.tensor(Y_test[i])\n",
    "#         images = images.view(1,1,len(images), len(images))\n",
    "        \n",
    "#         output = model(images)\n",
    "#         outputs.append(output)\n",
    "\n",
    "#         predicted = output.data > 0.5\n",
    "\n",
    "#         correct += (int(predicted[0]) == int(labels))\n",
    "\n",
    "# print('Accuracy of the network on the %d test images: %d %%' % (len(Y_test),\n",
    "#     100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
