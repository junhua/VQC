{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 3, 3])\n",
      "torch.Size([800, 5])\n",
      "torch.Size([200, 3, 3])\n",
      "torch.Size([200, 5])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "data = {}\n",
    "\n",
    "with open('tetris_train.json') as json_file:\n",
    "    data['train'] = json.load(json_file)\n",
    "\n",
    "with open('tetris_test.json') as json_file:\n",
    "    data['test'] = json.load(json_file)\n",
    "\n",
    "\n",
    "labels = {\n",
    "    'S': [0,0,0,0,1],\n",
    "    'T': [0,0,0,1,0],\n",
    "    'L': [0,0,1,0,0],\n",
    "    'O': [0,1,0,0,0],\n",
    "    'I': [1,0,0,0,0]\n",
    "}\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "\n",
    "for key in data['train'].keys():\n",
    "    X_train.extend(data['train'][key])\n",
    "    for _ in range(len(data['train'][key])):\n",
    "        Y_train.append(labels[key])\n",
    "\n",
    "for key in data['test'].keys():\n",
    "    X_test.extend(data['test'][key])\n",
    "    for _ in range(len(data['test'][key])):\n",
    "        Y_test.append(labels[key])\n",
    "\n",
    "\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "Y_train = torch.FloatTensor(Y_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "Y_test = torch.FloatTensor(Y_test)\n",
    "\n",
    "print(X_train.size())\n",
    "print(Y_train.size())\n",
    "print(X_test.size())\n",
    "print(Y_test.size())\n",
    "\n",
    "# print(X_train[-5:], Y_train[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 2, 3, padding=1)\n",
    "        self.mp1 = nn.MaxPool2d(3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(2, 3, 3, padding=1)\n",
    "        self.mp2 = nn.MaxPool2d(3, stride=1, padding=1)\n",
    "        self.mp = nn.MaxPool2d(2, stride=1)\n",
    "        self.fc = nn.Linear(27, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = self.mp1(F.relu(self.conv1(x)))\n",
    "        x = self.mp2(F.relu(self.conv2(x)))       \n",
    "        x = x.view(in_size, -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = ConvNet()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.5, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "#\n",
    "# Print number of parameters\n",
    "#\n",
    "# for item in list(ConvNet().parameters()):\n",
    "#     print (item)\n",
    "# print(list(ConvNet().parameters()))\n",
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "\n",
    "get_n_params(ConvNet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 141.853\n",
      "Epoch: 200, Loss: 138.864\n",
      "Epoch: 300, Loss: 141.783\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# \n",
    "# Training\n",
    "# \n",
    "results = {} #{iter: [loss, accuracy]}\n",
    "for epoch in range(10000):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    dataset = TensorDataset(X_train, Y_train)\n",
    "    train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=256,\n",
    "                          shuffle=True,\n",
    "                          num_workers=1)\n",
    "    \n",
    "    for _, data in enumerate(train_loader, 0):\n",
    "#     for i in range(len(Y_train)):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "#         inputs, labels = X_train[i], torch.tensor(Y_train[i])\n",
    "        inputs, labels = data\n",
    "#         inputs = inputs.view(256, 1, 3, 3)\n",
    "        for i in range(len(labels)):\n",
    "            x = inputs[i].view(1, 1, 3, 3)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, labels[i])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "    if epoch % 100 == 99:\n",
    "        print (\"Epoch: %d, Loss: %.3f\"%(epoch+1, running_loss))\n",
    "\n",
    "#         correct = 0.\n",
    "#         total = float(len(Y_test))\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for i in range(len(Y_test)):\n",
    "#                 images, labels = X_test[i], Y_test[i]\n",
    "#                 images = images.view(1, 1, 3, 3)\n",
    "\n",
    "#                 output = model(images)\n",
    "#                 predicted = output.data\n",
    "#                 correct += [int(item == predicted[0].max()) for item in predicted[0]] == labels.int().tolist()\n",
    "#                 accuracy = 100. * correct / total\n",
    "#         print('Accuracy of the network: %.2f %%' % (accuracy))\n",
    "\n",
    "#         results[epoch+1] = [running_loss, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
