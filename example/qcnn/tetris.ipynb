{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n",
      "Epoch: 100, Loss: 3.916\n",
      "Accuracy of the network: 50.50 %\n",
      "Epoch: 200, Loss: 3.881\n",
      "Accuracy of the network: 51.00 %\n",
      "Epoch: 300, Loss: 3.884\n",
      "Accuracy of the network: 49.50 %\n",
      "Epoch: 400, Loss: 3.890\n",
      "Accuracy of the network: 50.00 %\n",
      "Epoch: 500, Loss: 3.878\n",
      "Accuracy of the network: 52.00 %\n",
      "Epoch: 600, Loss: 3.886\n",
      "Accuracy of the network: 51.00 %\n",
      "Epoch: 700, Loss: 3.883\n",
      "Accuracy of the network: 51.00 %\n",
      "Epoch: 800, Loss: 3.881\n",
      "Accuracy of the network: 49.00 %\n",
      "Epoch: 900, Loss: 3.882\n",
      "Accuracy of the network: 49.50 %\n",
      "Epoch: 1000, Loss: 3.876\n",
      "Accuracy of the network: 48.50 %\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "data = {}\n",
    "\n",
    "with open('tetris_train.json') as json_file:\n",
    "    data['train'] = json.load(json_file)\n",
    "\n",
    "with open('tetris_test.json') as json_file:\n",
    "    data['test'] = json.load(json_file)\n",
    "\n",
    "labels = {'S': 0, 'T': 1, 'L': 2,'O': 3,'I': 4}\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = [],[],[],[]\n",
    "\n",
    "for key in data['train'].keys():\n",
    "    X_train.extend(data['train'][key])\n",
    "    for _ in range(len(data['train'][key])):\n",
    "        Y_train.append(labels[key])\n",
    "\n",
    "for key in data['test'].keys():\n",
    "    X_test.extend(data['test'][key])\n",
    "    for _ in range(len(data['test'][key])):\n",
    "        Y_test.append(labels[key])\n",
    "\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "Y_train = torch.FloatTensor(Y_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "Y_test = torch.FloatTensor(Y_test)\n",
    "\n",
    "# print(X_train.size()); print(Y_train.size()); print(X_test.size()); print(Y_test.size())\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 3, 3, padding=1)\n",
    "#         self.mp1 = nn.MaxPool2d(3, stride=1, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(3, 3, 3, padding=1)\n",
    "#         self.mp2 = nn.MaxPool2d(3, stride=1, padding=1)\n",
    "#         self.fc = nn.Linear(27, 5)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 2, 2)\n",
    "        self.conv2 = nn.Conv2d(2, 10, 2)\n",
    "        self.fc = nn.Linear(10, 5)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "#         x = self.mp1(F.relu(self.conv1(x)))\n",
    "#         x = self.mp2(F.relu(self.conv2(x)))       \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(in_size, -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = ConvNet()\n",
    "\n",
    "# criterion = nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.5, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "\n",
    "print(get_n_params(ConvNet()))\n",
    "\n",
    "# \n",
    "# Training\n",
    "# \n",
    "results = {} #{iter: [loss, accuracy]}\n",
    "for epoch in range(1000):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    dataset = TensorDataset(X_train, Y_train)\n",
    "    train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=200,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "    \n",
    "    for _, data in enumerate(train_loader, 0):\n",
    "#     for i in range(len(Y_train)):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "#         inputs, labels = X_train[i], torch.tensor(Y_train[i])\n",
    "        inputs, labels = data\n",
    "#         inputs = inputs.view(256, 1, 3, 3)\n",
    "#         for i in range(len(labels)):\n",
    "#             x = inputs[i].view(1, 1, 3, 3)\n",
    "\n",
    "        inputs = inputs.view(200,1,3,3)\n",
    "        labels = labels.long()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "#         print(outputs)\n",
    "#         print(labels[i])\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    if epoch % 100 == 99:\n",
    "        print (\"Epoch: %d, Loss: %.3f\"%(epoch+1, running_loss))\n",
    "\n",
    "        correct = 0.\n",
    "        total = float(len(Y_test))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(Y_test)):\n",
    "                images, labels = X_test[i], Y_test[i]\n",
    "                images = images.view(1, 1, 3, 3)\n",
    "#                 labels = labels.squeeze(0).max(0)[1]\n",
    "                output = model(images)\n",
    "                val, predicted = output.data.squeeze(0).max(0)\n",
    "                correct += int(predicted.float()==labels.float())\n",
    "                accuracy = 100. * correct / total\n",
    "        print('Accuracy of the network: %.2f %%' % (accuracy))\n",
    "\n",
    "        results[epoch+1] = [running_loss, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 0.031\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 200, Loss: 0.025\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 300, Loss: 0.018\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 400, Loss: 0.017\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 500, Loss: 0.013\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 600, Loss: 0.010\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 700, Loss: 0.011\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 800, Loss: 0.011\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 900, Loss: 0.010\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 1000, Loss: 0.011\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 1100, Loss: 0.009\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 1200, Loss: 0.009\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 1300, Loss: 0.010\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 1400, Loss: 0.009\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 1500, Loss: 0.008\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 1600, Loss: 0.008\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 1700, Loss: 0.008\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 1800, Loss: 0.009\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 1900, Loss: 0.008\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 2000, Loss: 0.008\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 2100, Loss: 0.007\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 2200, Loss: 0.005\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 2300, Loss: 0.005\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 2400, Loss: 0.004\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 2500, Loss: 0.004\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 2600, Loss: 0.005\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 2700, Loss: 0.003\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 2800, Loss: 0.004\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 2900, Loss: 0.003\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 3000, Loss: 0.003\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 3100, Loss: 0.003\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 3200, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 3300, Loss: 0.004\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 3400, Loss: 0.003\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 3500, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 3600, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 3700, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 3800, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 3900, Loss: 0.003\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 4000, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 4100, Loss: 0.003\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 4200, Loss: 0.003\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 4300, Loss: 0.003\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 4400, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 4500, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 4600, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 4700, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 4800, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 4900, Loss: 0.004\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 5000, Loss: 0.003\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 5100, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 5200, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 5300, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 5400, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 5500, Loss: 0.005\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 5600, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 5700, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 5800, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 5900, Loss: 0.004\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 6000, Loss: 0.003\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 6100, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 6200, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 6300, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 6400, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 6500, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 6600, Loss: 0.003\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 6700, Loss: 0.003\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 6800, Loss: 0.003\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 6900, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 7000, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 7100, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 7200, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n",
      "Epoch: 7300, Loss: 0.002\n",
      "Accuracy of the network: 100.00 %\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "data = {}\n",
    "\n",
    "with open('tetris_train.json') as json_file:\n",
    "    data['train'] = json.load(json_file)\n",
    "\n",
    "with open('tetris_test.json') as json_file:\n",
    "    data['test'] = json.load(json_file)\n",
    "\n",
    "labels = {\n",
    "    'S': [0,0,0,0,1],\n",
    "    'T': [0,0,0,1,0],\n",
    "    'L': [0,0,1,0,0],\n",
    "    'O': [0,1,0,0,0],\n",
    "    'I': [1,0,0,0,0]\n",
    "}\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = [],[],[],[]\n",
    "\n",
    "for key in data['train'].keys():\n",
    "    X_train.extend(data['train'][key])\n",
    "    for _ in range(len(data['train'][key])):\n",
    "        Y_train.append(labels[key])\n",
    "\n",
    "for key in data['test'].keys():\n",
    "    X_test.extend(data['test'][key])\n",
    "    for _ in range(len(data['test'][key])):\n",
    "        Y_test.append(labels[key])\n",
    "\n",
    "\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "Y_train = torch.FloatTensor(Y_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "Y_test = torch.FloatTensor(Y_test)\n",
    "\n",
    "# print(X_train.size()); print(Y_train.size()); print(X_test.size()); print(Y_test.size())\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 3, 3, padding=1)\n",
    "        self.mp1 = nn.MaxPool2d(3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(3, 3, 3, padding=1)\n",
    "        self.mp2 = nn.MaxPool2d(3, stride=1, padding=1)\n",
    "        self.fc = nn.Linear(27, 5)        \n",
    "        \n",
    "#         self.conv1 = nn.Conv2d(1, 5, 2)\n",
    "#         self.conv2 = nn.Conv2d(5, 10, 2)\n",
    "#         self.fc = nn.Linear(10, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = self.mp1(F.relu(self.conv1(x)))\n",
    "        x = self.mp2(F.relu(self.conv2(x)))       \n",
    "#         x = self.conv1(x)\n",
    "#         x = self.conv2(x)\n",
    "        x = x.view(in_size, -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = ConvNet()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.5, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "\n",
    "# get_n_params(ConvNet())\n",
    "\n",
    "# Training\n",
    "results = {} #{iter: [loss, accuracy]}\n",
    "for epoch in range(10000):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    dataset = TensorDataset(X_train, Y_train)\n",
    "    train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=200,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "    \n",
    "    for _, data in enumerate(train_loader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs = inputs.view(200,1,3,3)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    if epoch % 100 == 99:\n",
    "        print (\"Epoch: %d, Loss: %.3f\"%(epoch+1, running_loss))\n",
    "\n",
    "        correct = 0.\n",
    "        total = float(len(Y_test))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(Y_test)):\n",
    "                images, labels = X_test[i], Y_test[i]\n",
    "                images = images.view(1, 1, 3, 3)\n",
    "                labels = labels.max(0)[1]\n",
    "                output = model(images)\n",
    "#                 print(output, labels)\n",
    "                _, predicted = output.data.squeeze(0).max(0)\n",
    "        \n",
    "                correct += int(predicted.float()==labels.float())\n",
    "                accuracy = 100. * correct / total\n",
    "        print('Accuracy of the network: %.2f %%' % (accuracy))\n",
    "\n",
    "        results[epoch+1] = [running_loss, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
